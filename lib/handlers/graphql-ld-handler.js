'use strict';

const Handler = require('./handler');

// HACK
// const Client = require('graphql-ld').Client;

const JP = require('jsonpath');

// HACK
// const QueryEngineComunica = require('graphql-ld-comunica').QueryEngineComunica;

// Comunica query engines cache
// Saved by stringified list of sorted data sources

/**
 * Handles GraphQL-LD querying.
 *
 * @type {module.GraphQLLDHandler}
 */
module.exports = class GraphQLLDHandler extends Handler {

  constructor(logger) {
    super();

    this.logger = logger;
    this.comunicaEngineSourcesMap = {};

    // these were derived from captured loggings
    this.hardcodedQueryResults = {
      // '/' (projects) and '/research/projects'
      "{ id(_:KNOWS) hasProject { id @single name @single description @single image @single url @single @optional }}":
        JSON.parse(`{"data":[{"hasProject":[{"url":"https://www.imec-int.com/en/what-we-offer/research-portfolio/essence","name":"ESSENCE","description":"Human perspectives into a smart city platform that collects many media types, from personal devices and public displays to augmented reality. The ultimate goal is to create interactive stories embedded in the city environment about civic actions that boost engagement in these projects.","id":"https://data.knows.idlab.ugent.be/project/essence","image":"https://data.knows.idlab.ugent.be/person/office/essence.jpg"},{"url":"https://www.imec-int.com/en/what-we-offer/research-portfolio/dyversify","name":"DyVerSIFy","description":"Mining sensor data can give companies valuable insights into their assets and activities. But as technology advances, analyzing and visualizing the data becomes increasingly time- and resource-intensive. The DyVerSIFy project aims to develop software components and methodologies in the domains of dynamic visualization, adaptive anomaly detection and scalability to drive dynamic, adaptive and scalable sensor analytics.","id":"https://data.knows.idlab.ugent.be/project/dyversify","image":"https://data.knows.idlab.ugent.be/person/office/dyversify.jpg"},{"url":"https://www.imec-int.com/en/what-we-offer/research-portfolio/fast","name":"FAST","description":"Complicated rules, multiple contact points, numerous forms and applications and three administrative levels: processes as common as home renovations in Flanders require a lot of manual administrative work. To streamline customer journeys and simplify processes, municipalities and other public organizations would benefit from e-government applications. However, implementing these solutions is challenging, considering the lack of well-structured content and the need to integrate legacy systems. FAST aims to tackle the challenges to e-government adoption by creating an engine to automatically generate customer journeys from existing unstructured content – the ideal collection of digital interaction points between public services, organizations and citizens – for a range of public tasks.","id":"https://data.knows.idlab.ugent.be/project/fast","image":"https://data.knows.idlab.ugent.be/person/office/fast.jpg"},{"url":"https://knows.idlab.ugent.be/projects/mellon","name":"Mellon Scholarly Communication","description":"At the basis of this project is a vision of a researcher-centric, institution-enabled scholarly communication system, aligned with the Decentralized Web concepts and technologies, in which researchers use a personal domain and associated storage space as their long-term scholarly hub, and in which the core functions of scholarly communication are fulfilled in a decoupled manner.","id":"https://data.knows.idlab.ugent.be/project/mellon","image":"https://data.knows.idlab.ugent.be/person/office/mellon.jpg"}]}]}`),

      // '/' (news)
      "{ id(_:KNOWS) created { id @single name @single abstract @single articleBody @single }}":
        JSON.parse(`{"data":[{"created":[{"name":"Under construction.","abstract":"Stay tuned, we're still building this website..","id":"https://data.knows.idlab.ugent.be/news/1","articleBody":"\\nUnder construction\\n"}]}]}`),

      // '/research/topics'
      "{ id(_:KNOWS) topics { id @single name @single description @single contactPoint @single { id @single givenName @single familyName @single } }}":
        JSON.parse(`{"data":[{"topics":[{"contactPoint":{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},"name":"Scalable generation of knowledge graphs","id":"bc_2_n3-0","description":"In most cases knowledge graphs are generated from existing data sources using rules. Boggarts lavender robes, Hermione Granger Fantastic Beasts and Where to Find Them. Bee in your bonnet Hand of Glory elder wand, spectacles House Cup Bertie Bott’s Every Flavor Beans Impedimenta. Stunning spells tap-dancing spider Slytherin’s Heir mewing kittens Remus Lupin. Palominos scarlet train black robes, Metamorphimagus Niffler dead easy second bedroom. Padma and Parvati Sorting Hat Minister of Magic blue turban remember my last.\\nSquashy armchairs dirt on your nose brass scales crush the Sopophorous bean with flat side of silver dagger, releases juice better than cutting. Full moon Whomping Willow three turns should do it lemon drops. Locomotor trunks owl treats that will be 50 points, Mr. Potter. Witch Weekly, he will rise again and he will come for us, headmaster Erumpent horn. Fenrir Grayback horseless carriages ‘zis is a chance many would die for!"},{"contactPoint":{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},"name":"Scalable generation of knowledge graphs","id":"bc_2_n3-0","description":"In most cases knowledge graphs are generated from existing data sources using rules. Boggarts lavender robes, Hermione Granger Fantastic Beasts and Where to Find Them. Bee in your bonnet Hand of Glory elder wand, spectacles House Cup Bertie Bott’s Every Flavor Beans Impedimenta. Stunning spells tap-dancing spider Slytherin’s Heir mewing kittens Remus Lupin. Palominos scarlet train black robes, Metamorphimagus Niffler dead easy second bedroom. Padma and Parvati Sorting Hat Minister of Magic blue turban remember my last.\\nSquashy armchairs dirt on your nose brass scales crush the Sopophorous bean with flat side of silver dagger, releases juice better than cutting. Full moon Whomping Willow three turns should do it lemon drops. Locomotor trunks owl treats that will be 50 points, Mr. Potter. Witch Weekly, he will rise again and he will come for us, headmaster Erumpent horn. Fenrir Grayback horseless carriages ‘zis is a chance many would die for!"},{"contactPoint":{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},"name":"Scalable generation of knowledge graphs","id":"bc_2_n3-0","description":"In most cases knowledge graphs are generated from existing data sources using rules. Boggarts lavender robes, Hermione Granger Fantastic Beasts and Where to Find Them. Bee in your bonnet Hand of Glory elder wand, spectacles House Cup Bertie Bott’s Every Flavor Beans Impedimenta. Stunning spells tap-dancing spider Slytherin’s Heir mewing kittens Remus Lupin. Palominos scarlet train black robes, Metamorphimagus Niffler dead easy second bedroom. Padma and Parvati Sorting Hat Minister of Magic blue turban remember my last.\\nSquashy armchairs dirt on your nose brass scales crush the Sopophorous bean with flat side of silver dagger, releases juice better than cutting. Full moon Whomping Willow three turns should do it lemon drops. Locomotor trunks owl treats that will be 50 points, Mr. Potter. Witch Weekly, he will rise again and he will come for us, headmaster Erumpent horn. Fenrir Grayback horseless carriages ‘zis is a chance many would die for!"},{"contactPoint":{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},"name":"Scalable generation of knowledge graphs","id":"bc_2_n3-0","description":"In most cases knowledge graphs are generated from existing data sources using rules. Boggarts lavender robes, Hermione Granger Fantastic Beasts and Where to Find Them. Bee in your bonnet Hand of Glory elder wand, spectacles House Cup Bertie Bott’s Every Flavor Beans Impedimenta. Stunning spells tap-dancing spider Slytherin’s Heir mewing kittens Remus Lupin. Palominos scarlet train black robes, Metamorphimagus Niffler dead easy second bedroom. Padma and Parvati Sorting Hat Minister of Magic blue turban remember my last.\\nSquashy armchairs dirt on your nose brass scales crush the Sopophorous bean with flat side of silver dagger, releases juice better than cutting. Full moon Whomping Willow three turns should do it lemon drops. Locomotor trunks owl treats that will be 50 points, Mr. Potter. Witch Weekly, he will rise again and he will come for us, headmaster Erumpent horn. Fenrir Grayback horseless carriages ‘zis is a chance many would die for!"},{"contactPoint":{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},"name":"Publishing knowledge graphs on the Web","id":"bc_2_n3-1","description":"Determining the best way to publish knowledge graphs is not trivial: some prefer very specific APIs that can only answer well-standardized questions, while others prefer to work with a data dump to answer any question on their own machine. Our approach is slightly different: we research Web APIs where everyone can ask any question by fetchin the right fragments of the data just in time."},{"name":"Query processing over decentralized knowledge graphs","contactPoint":{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"},"id":"bc_2_n3-2","description":"Knowledge graphs are published on the Web in different ways. In order to extract facts from these knowledge graphs, intelligent querying algorithms are required that can handle the heterogeneity in terms of knowledge graph publishing interfaces. Furthermore, since the whole Web can be seen as a decentralized knowledge graph, we need techniques that can handle federated querying over large numbers of sources. Instead of requiring all of this data to be indexed beforehand, our approach involves exploiting the decentralized nature of the Web, and moving querying intelligence from server to client."},{"name":"Reasoning over knowledge graphs","contactPoint":{"givenName":"Doerthe","familyName":"Arndt","id":"https://data.knows.idlab.ugent.be/person/doerthe/#me"},"id":"bc_2_n3-3","description":"Data in knowledge graphs can be represented in different ways using differen vocabularies or simply different constructs. \\n    Facts often imply other facts. If we for example know that Bart is the son of Homer and that Homer is male, we can derive that Homer is the father of Bart. \\n    This generation of new knowlege based on existing knowledge is called reasoning. Reasoning can be performed based on different techniques and approaches. In our lab we mostly focus on \\n    rule-based reasoning. That means, possible kinds of derivations are expressed in logical rules which can be applied subsequently in order to gain new insides about data but also to, for example, translate between \\n    one vocabulary to another.\\n    "},{"contactPoint":{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},"name":"Generating knowledge graphs","id":"bc_2_n3-4","description":"Determining the best way to generate knowledge graphs."}]}]}`),

      // '/research/publications'
      "{ id(_:KNOWS) contributedTo { id @single name @single abstract @single authors { id @single givenName @single familyName @single } isPartOf @single { name @single } about { name } }}":
        JSON.parse(`{"data":[{"contributedTo":[{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Tom","familyName":"Seymoens","id":"https://data.verborgh.org/people/tom_seymoens"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Dimitri","familyName":"Schuurman","id":"https://data.verborgh.org/people/dimitri_schuurman"},{"givenName":"Aron-Levi","familyName":"Herregodts","id":"https://data.verborgh.org/people/aron_levi_herregodts"},{"givenName":"Ben","familyName":"De Meester","id":"http://ben.de-meester.org/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1016/j.websem.2017.12.003","about":[{"name":["visualization","RML","rules","research","Linked Data"]}],"isPartOf":{"name":"Journal of Web Semantics"},"abstract":"Visual tools are implemented to help users in defining how to generate Linked Data from raw data. This is possible thanks to mapping languages which enable detaching mapping rules from the implementation that executes them. However, no thorough research has been conducted so far on how to visualize such mapping rules, especially if they become large and require considering multiple heterogeneous raw data sources and transformed data values. In the past, we proposed the RMLEditor, a visual graph-based user interface, which allows users to easily create mapping rules for generating Linked Data from raw data. In this paper, we build on top of our existing work: we (i) specify a visual notation for graph visualizations used to represent mapping rules, (ii) introduce an approach for manipulating rules when large visualizations emerge, and (iii) propose an approach to uniformly visualize data fraction of raw data sources combined with an interactive interface for uniform data fraction transformations. We perform two additional comparative user studies. The first one compares the use of the visual notation to present mapping rules to the use of a mapping language directly, which reveals that the visual notation is preferred. The second one compares the use of the graph-based RMLEditor for creating mapping rules to the form-based RMLx Visual Editor, which reveals that graph-based visualizations are preferred to create mapping rules through the use of our proposed visual notation and uniform representation of heterogeneous data sources and data values.","name":"Specification and Implementation of Mapping Rule Visualization and Editing: MapVOWL and the RMLEditor"},{"authors":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Julián","familyName":"Rojas Meléndez","id":"https://julianrojas.org/#me"},{"givenName":"Gayane","familyName":"Sedrakyan","id":"https://data.verborgh.org/people/gayane_sedrakyan"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-98192-5_28","about":[{"name":["World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 15th ESWC: Posters and Demos"},"abstract":"The road to publishing public streaming data on the Web is paved with trade-offs that determine its viability. The cost of unrestricted query answering on top of data streams, may not be affordable for all data publishers. Therefore, public streams needs to be funded in a sustainable fashion to remain online. In this paper we introduce an overview of possible query answering features for live time series as multidimensional interfaces. For example, from a live parking availability data stream, pre-calculated time constrained statistical indicators or geographically classified data can be provided to clients on demand. Furthermore, we demonstrate the initial developments of a Linked Time Series server that supports such features through an extensible modular architecture. Benchmarking the costs associated to each of these features allows to weigh the trade-offs inherent to publishing live time series and establishes the foundations to create a decentralized and sustainable ecosystem for live data streams on the Web.","name":"Supporting sustainable publishing and consuming of live Linked Time Series Streams"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Ben","familyName":"De Meester","id":"http://ben.de-meester.org/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-98192-5_40","about":[{"name":["R2RML","RML","annotation","rules","Linked Data"]}],"isPartOf":{"name":"Proceedings of the 15th ESWC: Posters and Demos"},"abstract":"Linked Data is often generated based on a set of declarative rules using languages such as R2RML and RML. These languages are built with machine-processability in mind. It is thus not always straightforward for users to define or understand rules written in these languages, preventing them from applying the desired annotations to the data sources. In the past, graphical tools were proposed. However, next to users who prefer a graphical approach, there are users who desire to understand and define rules via a text-based approach. For the latter, we introduce an enhancement to their workflow. Instead of requiring users to manually write machine-processable rules, we propose writing human-friendly rules, and generate machine-processable rules based on those human-friendly rules. At the basis is YARRRML: a human-readable text-based representation for declarative generation rules. We propose a novel browser-based integrated development environment called “Matey”, showcasing the enhanced workflow. In this work, we describe our demo. Users can experience first hand how to generate triples from data in different formats by using YARRRML’s representation of the rules. The actual machine-processable rules remain completely hidden when editing. Matey shows that writing human-friendly rules enhances the workflow for a broader range of users. As a result, more desired annotations will be added to the data sources which leads to more desired Linked Data.","name":"Declarative Rules for Linked Data Generation at your Fingertips!"},{"authors":[{"givenName":"Sven","familyName":"Lieber","id":"https://sven-lieber.org/profile#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-98192-5_8","about":[{"name":["reuse","SPARQL","research"]}],"isPartOf":{"name":"Proceedings of the 15th ESWC: Posters and Demos"},"abstract":"Data management increasingly demands transparency with respect to data processing. Various stakeholders need information tailored to their needs, e.g. data management plans (DMP) for funding agencies or privacy policies for the public. DMPs and privacy policies are just two examples of documents describing aspects of data processing. Dedicated tools to create both already exist. However, creating each of them manually or semi-automatically remains a repetitive and cognitively challenging task. We propose a data-driven approach that semantically represents the data processing itself as workflows and serves as a base for different kinds of result-sets, generated with SPARQL, i.e. DMPs. Our approach is threefold: (i) users with domain knowledge semantically represent workflow components; (ii) other users can reuse these components to describe their data processing via semantically enhanced workflows; and, based on the semantic workflows, (iii) result-sets are automatically generated on-demand with SPARQL queries. This paper demonstrates our tool that implements the proposed approach, based on a use-case of a researcher who needs to provide a DMP to a funding agency to approve a proposed research project.","name":"SeGoFlow: A Semantic Governance Workflow Tool"},{"authors":[{"givenName":"Thomas","familyName":"Steiner","id":"http://tomayac.com/thomas_steiner.rdf#me"},{"givenName":"Sam","familyName":"Coppens","id":"https://data.verborgh.org/people/sam_coppens"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Joaquim","familyName":"Gabarró Vallés","id":"https://data.verborgh.org/people/joaquim_gabarro_valles"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Davy","familyName":"Van Deursen","id":"https://data.verborgh.org/people/davy_van_deursen"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-662-46641-4","about":[{"name":["RESTdesc","REST","World Wide Web","Web"]}],"isPartOf":{"name":"The Semantic Web: ESWC 2012 Satellite Events"},"abstract":"If we want automated agents to consume the Web, they need to understand what a certain service does and how it relates to other services and data. The shortcoming of existing service description paradigms is their focus on technical aspects instead of the functional aspect—what task does a service perform, and is this a match for my needs? This paper summarizes our recent work on RESTdesc, a semantic service description approach that centers on functionality. It has a solid foundation in logics, which enables advanced service matching and composition, while providing elegant and concise descriptions, responding to the demands of automated clients on the future Web of Agents.","name":"RESTdesc—A Functionality-Centered Approach to Semantic Service Description and Composition"},{"authors":[{"givenName":"Thomas","familyName":"Steiner","id":"http://tomayac.com/thomas_steiner.rdf#me"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Joaquim","familyName":"Gabarró Vallés","id":"https://data.verborgh.org/people/joaquim_gabarro_valles"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-662-46641-4_20","about":[{"name":["RESTdesc","hypermedia","REST","Linked Data","World Wide Web","Web"]}],"isPartOf":{"name":"The Semantic Web: ESWC 2012 Satellite Events"},"abstract":"In an often retweeted Twitter post, entrepreneur and software architect Inge Henriksen described the relation of Web 1.0 to Web 3.0 as: “Web 1.0 connected humans with machines. Web 2.0 connected humans with humans. Web 3.0 connects machines with machines.” On the one hand, an incredible amount of valuable data is described by billions of triples, machine-accessible and interconnected thanks to the promises of Linked Data. On the other hand, REST is a scalable, resource-oriented architectural style that, like the Linked Data vision, recognizes the importance of links between resources. Hypermedia APIs are resources, too—albeit dynamic ones—and unfortunately, neither Linked Data principles, nor the REST-implied self-descriptiveness of hypermedia APIs sufficiently describe them to allow for long-envisioned realizations like automatic service discovery and composition. We argue that describing inter-resource links—similarly to what the Linked Data movement has done for data—is the key to machine-driven consumption of APIs In this paper, we explain how the description format RESTdesc captures the functionality of APIs by explaining the effect of dynamic interactions, effectively complementing the Linked Data vision.","name":"Linked Data and Linked APIs: Similarities, Differences, and Challenges"},{"authors":[{"givenName":"Tom","familyName":"Creighton","id":"https://data.verborgh.org/people/tom_creighton"},{"givenName":"Sébastien","familyName":"Peyrard","id":"https://data.verborgh.org/people/sebastien_peyrard"},{"givenName":"Sam","familyName":"Coppens","id":"https://data.verborgh.org/people/sam_coppens"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Rebecca","familyName":"Guenther","id":"https://data.verborgh.org/people/rebecca_guenther"},{"givenName":"Kevin","familyName":"Ford","id":"https://data.verborgh.org/people/kevin_ford"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/s00799-014-0136-9","about":[{"name":["archiving","provenance","metadata","World Wide Web","Web"]}],"isPartOf":{"name":"International Journal on Digital Libraries"},"abstract":"In this article, we present PREMIS OWL. This is a semantic formalisation of the PREMIS 2.2 data dictionary of the Library of Congress. PREMIS 2.2 are metadata implementation guidelines for digitally archiving information for the long term. Nowadays, the need for digital preservation is growing. A lot of the digital information produced merely a decade ago is in danger of getting lost as technologies are changing and getting obsolete. This also threatens a lot of information from heritage institutions. PREMIS OWL is a semantic long-term preservation schema. Preservation metadata are actually a mixture of provenance information, technical information on the digital objects to be preserved and rights information. PREMIS OWL is an OWL schema that can be used as data model supporting digital archives. It can be used for dissemination of the preservation metadata as Linked Open Data on the Web and, at the same time, for supporting semantic web technologies in the preservation processes. The model incorporates 24 preservation vocabularies, published by the LOC as SKOS vocabularies. Via these vocabularies, PREMIS descriptions from different institutions become highly interoperable. The schema is approved and now managed by the Library of Congress. The PREMIS OWL schema is published at http://www.loc.gov/premis/rdf/v1.","name":"PREMIS OWL"},{"authors":[{"givenName":"Sven","familyName":"Lieber","id":"https://sven-lieber.org/profile#me"},{"givenName":"Tom","familyName":"De Nies","id":"https://data.verborgh.org/people/tom_de_nies"},{"givenName":"Peter","familyName":"Fischer","id":"https://data.verborgh.org/people/peter_fischer"},{"givenName":"Io","familyName":"Taxidou","id":"https://data.verborgh.org/people/io_taxidou"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/s10619-017-7211-3","about":[{"name":["information diffusion","publication","provenance","social media","research","Facebook","World Wide Web","Web"]}],"isPartOf":{"name":"Distributed and Parallel Databases"},"abstract":"Fast, massive, and viral data diffused on social media affects a large share of the online population, and thus, the (prospective) information diffusion mechanisms behind it are of great interest to researchers. The (retrospective) provenance of such data is equally important because it contributes to the understanding of the relevance and trustworthiness of the information. Furthermore, computing provenance in a timely way is crucial for particular use cases and practitioners, such as online journalists that promptly need to assess particular pieces of information. Social media currently provide insufficient mechanisms for provenance tracking, publication and generation, while state-of-the-art on social media research focuses mainly on explicit diffusion mechanisms (like retweets in Twitter or reshares in Facebook).The implicit diffusion mechanisms remain understudied due to the difficulties of being captured and properly understood. From a technical side, the state of the art for provenance reconstruction evaluates small datasets after the fact, sidestepping requirements for scale and speed of current social media data. In this paper, we investigate the mechanisms of implicit information diffusion by computing its fine-grained provenance. We prove that explicit mechanisms are insufficient to capture influence and our analysis unravels a significant part of implicit interactions and influence in social media. Our approach works incrementally and can be scaled up to cover a truly Web-scale scenario like major events. The results show that (on a single machine) we can process datasets consisting of up to several millions of messages at rates that cover bursty behaviour, without compromising result quality. By doing that, we provide to online journalists and social media users in general, fine grained provenance reconstruction which sheds lights on implicit interactions not captured by social media providers. These results are provided in an online fashion which also allows for fast relevance and trustworthiness assessment.","name":"Web-scale Provenance Reconstruction of Implicit Information Diffusion on Social Media"},{"authors":[{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Davy","familyName":"Van Deursen","id":"https://data.verborgh.org/people/davy_van_deursen"},{"givenName":"Chris","familyName":"Poppe","id":"https://data.verborgh.org/people/chris_poppe"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/s11042-010-0709-6","about":[{"name":["annotation","Web services","Web service","metadata","Semantic Web","World Wide Web","Web"]}],"isPartOf":{"name":"Multimedia Tools and Applications"},"abstract":"Automatic generation of metadata, facilitating the retrieval of multimedia items, potentially saves large amounts of manual work. However, the high specialization degree of feature extraction algorithms makes them unaware of the context they operate in, which contains valuable and often necessary information. In this paper, we show how Semantic Web technologies can provide a context that algorithms can interact with. We propose a generic problem-solving platform that uses Web services and various knowledge sources to find solutions to complex requests. The platform employs a reasoner-based composition algorithm, generating an execution plan that combines several algorithms as services. It then supervises the execution of this plan, intervening in case of errors or unexpected behavior. We illustrate our approach by a use case in which we annotate the names of people depicted in a photograph.","name":"Enabling context-aware multimedia annotation by a novel generic semantic problem-solving platform"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Riccardo","familyName":"Tommasini","id":"https://data.verborgh.org/people/riccardo_tommasini"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Emanuele","familyName":"Della Valle","id":"https://data.verborgh.org/people/emanuele_della_valle"},{"givenName":"Ben","familyName":"De Meester","id":"http://ben.de-meester.org/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/tommasini_iswc_demo_2017/#publication","about":[{"name":["interoperability","research","Linked Data","RDF"]}],"isPartOf":{"name":"Proceedings of the 16th International Semantic Web Conference: Posters and Demos"},"abstract":"Containers – lightweight, stand-alone software executables – are everywhere. Industries exploit container managers to orchestrate complex cloud infrastructures and researchers in academia use them to foster reproducibility of computational experiments. Among existing solutions, Docker is the de facto standard in the container industry. In this paper, we advocate the value of applying the Linked Data paradigm to the container ecosystem’s building scripts, as it will allow adding additional knowledge, ease decentralized references, and foster interoperability. In particular we defined a vocabulary Dockeronto that allows to semantically annotate Dockerfiles.","name":"Representing Dockerfiles in RDF"},{"authors":[{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"},{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/taelman_iswc_demo_2016/#publication","about":[{"name":["publication","Linked Data","RDF","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 15th International Semantic Web Conference: Posters and Demos"},"abstract":"The world contains a large amount of sensors that produce new data at a high frequency. It is currently very hard to find public services that expose these measurements as dynamic Linked Data. We investigate how sensor data can be published continuously on the Web at a low cost. This paper describes how the publication of various sensor data sources can be done by continuously mapping raw sensor data to RDF and inserting it into a live, low-cost server. This makes it possible for clients to continuously evaluate dynamic queries using public sensor data. For our demonstration, we will illustrate how this pipeline works for the publication of temperature and humidity data originating from a microcontroller, and how it can be queried.","name":"Querying Dynamic Datasources with Continuously Mapped Sensor Data"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/heyvaert_ld4ie_2017/#publication","about":[{"name":["RML","rules","Linked Data"]}],"isPartOf":{"name":"Proceedings of the 5th International Workshop on Linked Data for Information Extraction"},"abstract":"Linked Data can be generated by applying mapping rules on existing (semi-)structured data. The manual creation of these rules involves a costly process for users. Therefore, (semi-)automatic approaches have been developed to assist users. Although, they provide promising results, in use cases where examples of the desired Linked Data are available they do not use the knowledge provided by these examples, resulting in Linked Data that might not be as desired. This in turn requires manual updates of the rules. These examples can in certain cases be easy to create and offer valuable knowledge relevant for the mapping process, such as which data corresponds to entities and attributes, how this data is annotated and modeled, and how different entities are linked to each other. In this paper, we introduce a semi-automatic approach to create rules based on examples for both the existing data and corresponding Linked Data. Furthermore, we made the approach available via the RMLEditor, making it readily accessible for users through a graphical user interface. The proposed approach provides a first attempt to generate a complete Linked Dataset based on user-provided examples, by creating an initial set of rules for the users.","name":"Semi-Automatic Example-Driven Linked Data Mapping Creation"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/heyvaert_jist_2016/#publication","about":[{"name":["Linked Data","RDF"]}],"isPartOf":{"name":"Proceedings of the Joint International Semantic Technology Conference"},"abstract":"Generating Linked Data based on existing data sources requires the modeling of their information structure. This modeling needs the identification of potential entities, their attributes and the relationships between them and among entities. For databases this identification is not required, because a data schema is always available. However, for other data formats, such as hierarchical data, this is not always the case. Therefore, analysis of the data is required to support RDF term and data type identification. We introduce a tool that performs such an analysis on hierarchical data. It implements the algorithms, Daro and S-Daro, proposed in this paper. Based on our evaluation, we conclude that S-Daro offers a more scalable solution regarding run time, with respect to the dataset size, and provides more complete results.","name":"Data Analysis of Hierarchical Data for RDF Term Identification"},{"authors":[{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"},{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/heyvaert_iswc_demo_2016/#publication","about":[{"name":["RML","interoperability","communication","reuse","Triple Pattern Fragments","research","Linked Data","RDF"]}],"isPartOf":{"name":"Proceedings of the 15th International Semantic Web Conference: Posters and Demos"},"abstract":"As the amount of generated sensor data is increasing, semantic interoperability becomes an important aspect in order to support efficient data distribution and communication. Therefore, the integration and fusion of (sensor) data is important, as this data is coming from different data sources and might be in different formats. Furthermore, reusable and extensible methods for this integration and fusion are required in order to be able to scale with the growing number of applications that generate semantic sensor data. Current research efforts allow to map sensor data to Linked Data in order to provide semantic interoperability. However, they lack support for multiple data sources, hampering the integration and fusion. Furthermore, the used methods are not available for reuse or are not extensible, which hampers the development of applications. In this paper, we describe how the RDF Mapping Language (RML) and a Triple Pattern Fragments (TPF) server are used to address these shortcomings. The demonstration consists of a micro controller that generates sensor data. The data is captured and mapped to RDF triples using module-specific RML mappings, which are queried from a TPF server.","name":"Linked Sensor Data Generation using Queryable RML Mappings"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/heyvaert_iswc_2015/#publication","about":[{"name":["rules","Linked Data","Semantic Web","RDF","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 14th International Semantic Web Conference: Posters and Demos"},"abstract":"Obtaining Linked Data by modeling domain-level knowledge derived from input data is not straightforward for data publishers, especially if they are not Semantic Web experts. Developing user interfaces that support domain experts to semantically annotate their data became feasible, as the mapping rules were abstracted from their execution. However, most existing approaches reflect how mappings are typically executed: they offer a single linear workflow, triggered by a particular data source. Alternative approaches were neither thoroughly investigated yet, nor incorporated in any of the existing user interfaces for mappings. In this paper, we generalize the two prevalent approaches for generating mappings of data in databases: database-driven and ontology-driven, to be applicable for any other data structure; and introduce two approaches: model-driven and result-driven.","name":"Towards Approaches for Generating RDF Mapping Definitions"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/heyvaert_iesd_2015/#publication","about":[{"name":["RML","Linked Data","Semantic Web","RDF","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 4th Workshop on Intelligent Exploration of Semantic Data"},"abstract":"Modeling domain knowledge as Linked Data is not straightforward for data publishers, because they are domain experts and not Semantic Web specialists. Most approaches that map data to its RDF representation still require users to have knowledge of the underlying implementations, as the mapping definitions remained, so far, tight to their execution. Defining mapping languages enables to decouple the mapping definitions from the implementation. However, user interfaces that enable domain experts to model knowledge and, thus, intuitively define such mapping definitions, based on available input sources, were not thoroughly investigated yet. This paper introduces a non-exhaustive list of desired features to be supported by such a mapping editor, independently of the underlying mapping language; and presents the RMLEditor as prototype interface that implements these features with RML as its underlying mapping language.","name":"Towards a Uniform User Interface for Editing Mapping Definitions"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Ben","familyName":"De Meester","id":"http://ben.de-meester.org/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/dimou_ldow_2018/#publication","about":[{"name":["Linked Data generation","Linked Data"]}],"isPartOf":{"name":"Proceedings of the 11th Workshop on Linked Data on the Web"},"abstract":"Generating Linked Data remains a complicated and intensive engineering process. While different factors determine how a Linked Data generation algorithm is designed, potential alternatives for each factor are currently not considered when designing the tools’ underlying algorithms. Certain design patterns are frequently applied across different tools, covering certain alternatives of a few of these factors, whereas other alternatives are never explored. Consequently, there are no adequate tools for Linked Data generation for certain occasions, or tools with inadequate and inefficient algorithms are chosen. In this position paper, we determine such factors, based on our experiences, and present a preliminary list. These factors could be considered when a Linked Data generation algorithm is designed or a tool is chosen. We investigated which factors are covered by widely known Linked Data generation tools and concluded that only certain design patterns are frequently encountered. By these means, we aim to point out that Linked Data generation is above and beyond bare implementations, and algorithms need to be thoroughly and systematically studied and exploited.","name":"What Factors Influence the Design of a Linked Data Generation Algorithm? "},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Wouter","familyName":"Maroy","id":"https://data.verborgh.org/people/wouter_maroy"},{"givenName":"Laurens","familyName":"De Graeve","id":"https://data.verborgh.org/people/laurens_de_graeve"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/dimou_iswc_demo_2016b/#publication","about":[{"name":["RML","Linked Data generation","publication","reuse","Linked Data","Semantic Web","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 15th International Semantic Web Conference: Posters and Demos"},"abstract":"Linked Data generation and publication remain challenging and complicated, in particular for data owners who are not Semantic Web experts or tech-savvy. The situation deteriorates when data from multiple heterogeneous sources, accessed via different interfaces, is integrated, and the Linked Data generation is a long-lasting activity repeated periodically, often adjusted and incrementally enriched with new data. Therefore, we propose the RMLWorkbench, a graphical user interface to support data owners administrating their Linked Data generation and publication workflow. The RMLWorkbench’s underlying language is RML, since it allows to declaratively describe the complete Linked Data generation workflow. Thus, any Linked Data generation workflow specified by a user can be exported and reused by other tools interpreting RML.","name":"Towards an Interface for User-Friendly Linked Data Generation Administration"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Ben","familyName":"De Meester","id":"http://ben.de-meester.org/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/demeester_voila_2018/#publication","about":[{"name":["Semantic Web","RDF","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 4th International Workshop on Visualization and Interaction for Ontologies and Linked Data"},"abstract":"Data quality is an important factor for the success of the envisaged Semantic Web. As machines are inherently intolerant at the interpretation of unexpected input, low quality data produces low quality results. Recently, constraint languages such as SHACL were proposed to assess the quality of data graphs, decoupled from the use case and the implementation. However, these constraint languages were designed with machine-processability in mind. Defining data shapes requires knowledge of the language’s syntax – usually RDF – and specification, which is not straightforward for domain experts, as they are not Semantic Web specialists. The notion of constraint languages is very recent: the W3C Recommendation for SHACL was finalized in 2017. Thus, user interfaces that enable domain experts to intuitively define such data shapes are not thoroughly investigated yet. In this paper, we present a non-exhaustive list of desired features to be supported by a user interface for editing data shapes. These features are applied to unSHACLed: a prototype interface with SHACL as its underlying constraint language. For specifying the features, we aligned existing work of ontology editing and linked data generation rule editing with data shape editing, and applied them using a drag-and-drop interface that combines data graph and data shape editing. This work can thus serve as a starting point for data shape editing interfaces.","name":"Towards a Uniform User Interface for Editing Data Shapes"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Ben","familyName":"De Meester","id":"http://ben.de-meester.org/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://ruben.verborgh.org/publications/demeester_kgb_2019/#publication","about":[{"name":["RDF"]}],"isPartOf":{"name":"Proceedings of First Knowledge Graph Building Workshop"},"abstract":"RDF generation processes are becoming more interoperable, reusable, and maintainable due to the increased usage of mapping languages: languages used to describe how to generate an RDF graph from (semi-)structured data. This leads to a rise of new mapping languages, each with different characteristics. However, it is not clear which mapping language can be used for a given task. Thus, a comparative framework is needed. In this paper, we investigate a set of mapping languages that inhibit complementary characteristics, and present an initial set of comparative characteristics based on requirements put forward by those mapping languages. Initial investigation found 9 broad characteristics, classified in 3 categories. To further formalize and complete the set of characteristics, further investigation is needed, requiring a joint effort of the community.","name":"Mapping languages: analysis of comparative characteristics"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Ben","familyName":"De Meester","id":"http://ben.de-meester.org/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.3233/SW-190358","about":[{"name":["annotation","rules"]}],"isPartOf":{"name":"Semantic Web Journal"},"abstract":"Knowledge graphs, which contain annotated descriptions of entities and their interrelations, are often generated using rules that apply semantic annotations to certain data sources. (Re)using ontology terms without adhering to the axioms defined by their ontologies results in inconsistencies in these graphs, affecting their quality. Methods and tools were proposed to detect and resolve inconsistencies, the root causes of which include rules and ontologies. However, these either require access to the complete knowledge graph, which is not always available in a time-constrained situation, or assume that only generation rules can be refined but not ontologies. In the past, we proposed a rule-driven method for detecting and resolving inconsistencies without complete knowledge graph access, but it requires a predefined set of refinements to the rules and does not guide users with respect to the order the rules should be inspected. We extend our previous work with a rule-driven method, called Resglass, that considers refinements for generation rules as well as ontologies. In this article, we describe Resglass, which includes a ranking to determine the order with which rules and ontology elements should be inspected, and its implementation. The ranking is evaluated by comparing the manual ranking of experts to our automatic ranking. The evaluation shows that our automatic ranking achieves an overlap of 80% with experts ranking, reducing this way the effort required during the resolution of inconsistencies in both rules and ontologies.","name":"Rule-driven inconsistency resolution for knowledge graph generation"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Wesley","familyName":"De Neve","id":"https://data.verborgh.org/people/wesley_de_neve"},{"givenName":"Tom","familyName":"De Nies","id":"https://data.verborgh.org/people/tom_de_nies"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Joachim","familyName":"Van Herwegen","id":"https://data.verborgh.org/people/joachim_van_herwegen"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Miel","familyName":"Vander Sande","id":"https://data.verborgh.org/people/miel_vander_sande"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.3233/978-1-61499-562-3-37","about":[{"name":["JavaScript","metadata","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 19th International Conference on Electronic Publishing"},"abstract":"Various methods are needed to extract information from current (digital) comics. Furthermore, the use of different (proprietary) formats by comic distribution platforms causes an overhead for authors. To overcome these issues, we propose a solution that makes use of the EPUB 3 specification, additionally leveraging the Open Web Platform to support animations, reading assistance, audio and multiple languages in a single format, by using our JavaScript library comicreader.js. We also provide administrative and descriptive metadata in the same format by introducing a new ontology: Dicera. Our solution is complementary to the current extraction methods, on the one hand because they can help with metadata creation, and on the other hand because the machine-understandable metadata alleviates their use. While the reading system support for our solution is currently limited, it can offer all features needed by current comic distribution platforms. When comparing comics generated by our solution to EPUB 3 textbooks, we observed an increase in file size, mainly due to the use of images. In future work, our solution can be further improved by extending the presentation features, investigating different types of comics, studying the use of new EPUB 3 extensions, and by incorporating it in digital book authoring environments.","name":"Using EPUB 3 and the Open Web Platform for Enhanced Presentation and Machine-Understandable Metadata for Digital Comics"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Wouter","familyName":"Maroy","id":"https://data.verborgh.org/people/wouter_maroy"},{"givenName":"Gerald","familyName":"Haesendonck","id":"https://data.verborgh.org/people/gerald_haesendonck"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1145/3323878.3325802","about":[{"name":["RML","RDF"]}],"isPartOf":{"name":"Proceedings of the International Workshop on Semantic Big Data"},"abstract":"To unlock the value of increasingly available data in high volumes, we need flexible ways to integrate data across different sources. While semantic integration can be provided through RDF generation, current generators insufficiently scale in terms of volume. Generators are limited by memory constraints. Therefore, we developed the RMLStreamer, a generator that parallelizes the ingestion and mapping tasks of RDF generation across multiple instances. In this paper, we analyze what aspects are parallelizable and we introduce an approach for parallel RDF generation. We describe how we implemented our proposed approach, in the frame of the RMLStreamer, and how the resulting scaling behavior compares to other RDF generators. The RMLStreamer ingests data at 50% faster rate than existing generators through parallel ingestion.","name":"Parallel RDF generation from heterogeneous big data"},{"authors":[{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"},{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-58694-6_1","about":[{"name":["Linked Data publication","XML","RML","Linked Data generation","Linked Data Fragments","Web API","Triple Pattern Fragments","Linked Data","Semantic Web","JSON","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 20th International Conference on Knowledge Engineering and Knowledge Management"},"abstract":"The process of extracting, structuring, and organizing knowledge from one or multiple data sources and preparing it for the Semantic Web requires a dedicated class of systems. They enable processing large and originally heterogeneous data sources and capturing new knowledge. Offering existing data as Linked Data increases its shareability, extensibility, and reusability. However, using Linking Data as a means to represent knowledge can be easier said than done. In this tutorial, we elaborate on the importance of semantically annotating data and how existing technologies facilitate their mapping to Linked Data. We introduce [R2]RML languages to generate Linked Data derived from different heterogeneous data sources (databases, XML, JSON, …) from different interfaces (documents, Web APIs, …). Those who are not Semantic Web experts can annotate their data with the RMLEditor, whose user interface hides all underlying Semantic Web technologies to data owners. Last, we show how to easily publish Linked Data on the Web as Triple Pattern Fragments. As a result, participants, independently of their knowledge background, can model, annotate and publish data on their own.","name":"Modeling, Generating, and Publishing Knowledge as Linked Data"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-47602-5_25","about":[{"name":["RML","Linked Data generation","Linked Data","Semantic Web","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 13th Extended Semantic Web Conference: Posters and Demos"},"abstract":"Linked Data is in many cases generated from (semi-)structured data. This generation is supported by several tools, a number of which use a mapping language to facilitate the Linked Data generation. However, knowledge of this language and other used technologies is required to use the tools, limiting their adoption by non-Semantic Web experts. We demonstrate the RMLEditor: a graphical user interface that utilizes graphs to easily visualize the mappings that deliver the rdf representation of the original data. The required amount of knowledge of the underlying mapping language and the used technologies is kept to a minimum. The RMLEditor lowers the barriers to create Linked Data by aiming to also facilitate the editing of mappings by non-experts.","name":"Graph-Based Editing of Linked Data Mappings using the RMLEditor"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Dimitri","familyName":"Schuurman","id":"https://data.verborgh.org/people/dimitri_schuurman"},{"givenName":"Aron-Levi","familyName":"Herregodts","id":"https://data.verborgh.org/people/aron_levi_herregodts"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-34129-3_43","about":[{"name":["RML","research","Linked Data","RDF"]}],"isPartOf":{"name":"The Semantic Web: Latest Advances and New Domains (ESWC 2016)"},"abstract":"Although several tools have been implemented to generate Linked Data from raw data, users still need to be aware of the underlying technologies and Linked Data principles to use them. Mapping languages enable to detach the mapping definitions from the implementation that executes them. However, no thorough research has been conducted on how to facilitate the editing of mappings. We propose the RMLEditor, a visual graph-based user interface, which allows users to easily define the mappings that deliver the RDF representation of the corresponding raw data. Neither knowledge of the underlying mapping language nor the used technologies is required. The RMLEditor aims to facilitate the editing of mappings, and thereby lowers the barriers to create Linked Data. The RMLEditor is developed for use by data specialists who are partners of (i) a companies-driven pilot and (ii) a community group. The current version of the RMLEditor was validated: participants indicate that it is adequate for its purpose and the graph-based approach enables users to conceive the linked nature of the data.","name":"RMLEditor: A Graph-based Mapping Editor for Linked Data Mappings"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-25639-9_13","about":[{"name":["DBpedia","Triple Pattern Fragments","SPARQL","World Wide Web","Web"]}],"isPartOf":{"name":"Proceedings of the 12th Extended Semantic Web Conference: Posters and Demos"},"abstract":"Data Catalog Vocabulary (DCAT) is a W3C specification to describe datasets published on the Web. However, these catalogs are not easily discoverable based on a user’s needs. In this paper, we introduce the Node.js module \\"dcat-merger\\" which allows a user agent to download and semantically merge different DCAT feeds from the Web into one DCAT feed, which can be republished. Merging the input feeds is followed by enriching them. Besides determining the subjects of the datasets, using DBpedia Spotlight, two extensions were built: one categorizes the datasets according to a taxonomy, and the other adds spatial properties to the datasets. These extensions require the use of information available in DBpedia’s SPARQL endpoint. However, public SPARQL endpoints often suffer from low availability, so a Triple Pattern Fragments alternative is used. However, the need for DCAT Merger sparks the discussion for more high level functionality to improve a catalog’s discoverability.","name":"Merging and Enriching DCAT Feeds to Improve Discoverability of Datasets"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-25518-7_14","about":[{"name":["RML","SPARQL","RDF"]}],"isPartOf":{"name":"Proceedings of the 12th Extended Semantic Web Conference: Semantic Publishing Challenge"},"abstract":"In this paper, we present our solution for the first task of the second edition of the Semantic Publishing Challenge. The task requires extracting and semantically annotating information regarding CEUR-WS workshops, their chairs and conference affiliations, as well as their papers and their authors, from a set of html-encoded workshop proceedings volumes. Our solution builds on last year’s submission, while we address a number of shortcomings, assess the generated dataset for its quality and publish the queries as SPARQL query templates. This is accomplished using the RDF Mapping Language (RML) to define the mappings, RMLProcessor to execute them, RDFUnit to both validate the mapping documents and assess the generated dataset’s quality, and The DataTank to publish the SPARQL query templates. This results in an overall improved quality of the generated dataset that is reflected in the query results.","name":"Semantically Annotating CEUR-WS Workshop Proceedings with RML"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Rik","familyName":"Van de Walle","id":"https://data.verborgh.org/people/rik_van_de_walle"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-319-24258-3_65","about":[{"name":["JavaScript","Linked Data"]}],"isPartOf":{"name":"Proceedings of the 10th European Conference on Technology Enhanced Learning"},"abstract":"Interest in eLearning environments is constantly increasing, as well as in digital textbooks and gamification. The advantages of gamification in the context of education have been proven. However, gamified educational material, such as digital textbooks and digital systems, are scarce. As an answer to the need for such material, the framework GEL (Gamification for EPUB using Linked Data) has been developed. GEL allows to incorporate gamification concepts in a digital textbook, using EPUB 3 and Linked Data. As part of GEL, we created the ontology GO (Gamification Ontology), representing the different gamification concepts, and a JavaScript library. Using GO allows to discover other gamified systems, to share gamification concepts between applications and to separate the processing and representation of the gamification concepts. Our library is interoperable with any JavaScript-based e-reader, which promotes its reusability.","name":"Linked Data-enabled Gamification in EPUB 3 for Educational Digital Textbooks"},{"authors":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Oscar","familyName":"Corcho","id":"https://data.verborgh.org/people/oscar_corcho"},{"givenName":"Freddy","familyName":"Priyatna","id":"https://data.verborgh.org/people/freddy_priyatna"},{"givenName":"Erik","familyName":"Mannens","id":"https://data.verborgh.org/people/erik_mannens"},{"givenName":"David","familyName":"Chaves-Fraga","id":"https://data.verborgh.org/people/david_chaves_fraga"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"id":"https://dx.doi.org/10.1007/978-3-030-21395-4_12","about":[{"name":["CARML","CSV","XML","R2RML","RMLMapper","RML","annotation","rules","programming","RDF","JSON"]}],"isPartOf":{"name":"Proceedings of the 1st Iberoamerican Knowledge Graphs and Semantic Web Conference"},"abstract":"Knowledge graphs are often generated using rules that apply semantic annotations to data sources. Software tools then execute these rules and generate or virtualize the corresponding RDF-based knowledge graph. RML is an extension of the W3C-recommended R2RML language, extending support from relational databases to other data sources, such as data in CSV, XML, and JSON format. As part of the R2RML standardization process, a set of test cases was created to assess tool conformance the specification. In this work, we generated an initial set of reusable test cases to assess RML conformance. These test cases are based on R2RML test cases and can be used by any tool, regardless of the programming language. We tested the conformance of two RML processors: the RMLMapper and CARML. The results show that the RMLMapper passes all CSV, XML, and JSON test cases, and most test cases for relational databases. CARML passes most CSV, XML, and JSON test cases regarding. Developers can determine the degree of conformance of their tools, and users determine based on conformance results to determine the most suitable tool for their use cases.","name":"Conformance Test Cases for the RDF Mapping Language (RML)"}]}]}`),

      // '/dev/software'
      "{ id(_:KNOWS) hasSoftware { type (_:Software) description @single name @single hasGit @optional @single { type(_:Git) url @single } }}":
        JSON.parse(`{"data":[{"hasSoftware":[{"hasGit":{"url":"https://github.com/comunica/"},"name":"Comunica","description":"A modular framework for querying Linked Data on the Web."},{"hasGit":{"url":"https://github.com/rmlio/rmlmapper-java"},"name":"RMLMapper","description":"The RMLMapper executes RML rules to generate high quality Linked Data from multiple originally (semi-)structured data sources."},{"hasGit":{"url":"https://github.com/RMLio/RMLStreamer"},"name":"RMLStreamer","description":"The RMLStreamer executes RML rules to generate high quality Linked Data from multiple originally (semi-)structured data sources in a streaming way."},{"hasGit":{"url":"https://github.com/LinkedDataFragments/Server.js"},"name":"Linked Data Fragments Server","description":"A Triple Pattern Fragments server for Node.js"},{"description":"A Web app to create RML rules.","name":"RMLEditor"},{"hasGit":{"url":"https://github.com/rmlio/yarrrml-parser"},"name":"YARRRML Parser","description":"A YARRRML parser library and CLI in Javascript"},{"hasGit":{"url":"https://github.com/rubensworks/ScholarMarkdown"},"name":"ScholarMarkdown","description":"A framework for writing markdown-based scholarly articles."},{"hasGit":{"url":"https://github.com/rubensworks/graphql-ld.js"},"name":"GraphQL-LD","description":"Linked Data Querying with GraphQL."},{"hasGit":{"url":"https://github.com/rdfostrich/ostrich"},"name":"GraphQL-LD","description":"Linked Data Querying with GraphQL."},{"description":"An RDF triple store that allows multiple versions of a dataset to be stored and queried at the same time.","name":"OSTRICH"}]}]}`),

      // '/dev/tutorials'
      "{ id(_:KNOWS) hasTutorial { type (_:Tutorial) description @single @optional name @single url @single }}":
        JSON.parse(`{"data":[{"hasTutorial":[{"description":"Walder offers an easy way to set up a website or Web API on top of decentralized knowledge graphs. Knowledge graphs incorporate data together with the meaning of that data. This makes it possible to combine data from multiple knowledge graphs, even if different, independent parties maintain or host them. Knowledge graphs can be hosted via Solid PODs, SPARQL endpoints, Triple Pattern Fragments interfaces, RDF files, and so on. This tutorial introduces you to Walder.","name":"Getting started with Walder","url":"https://pieterheyvaert.com/blog/2020/08/31/getting-started-with-walder/"},{"name":"Getting started with YARRRML","url":"http://rml.io/yarrrml/tutorial/getting-started/"},{"name":"An Introduction To GraphQL","url":"https://www.ida.liu.se/research/semanticweb/events/GraphQLTutorialAtISWC2019.shtml"},{"description":"This is a tutorial showcasing in which ways you can query data using Comunica. There will be several (mostly) separate parts in this tutorial, some of them requiring programming, and others requiring configuration of existing solutions.","name":"Comunica tutorial: Querying Data","url":"https://github.com/comunica/Tutorial-Comunica-Querying-Data/wiki/Comunica-tutorial:-Querying-Data"},{"description":"This is a tutorial on Comunica in which a new actor is created that (naively) implements the SPARQL REDUCED operator. This tutorial focuses on the case where you want to develop your actor externally outside of the Comunica repository. If you want to contribute an actor to the Comunica repository, please refer to the tutorial on Developing a feature for Comunica.","name":"Comunica tutorial: Creating a REDUCED actor","url":"https://github.com/comunica/Tutorial-Comunica-Reduced-Actor/wiki/Comunica-tutorial:-Creating-a-REDUCED-actor"},{"description":"This is a tutorial on how to get started with Solid. This tutorial will cover the basics around Solid data pod and application usage.","name":"Getting started with Solid","url":"https://github.com/comunica/Tutorial-Solid-Getting-Started/wiki/Tutorial-walkthrough"},{"description":"This is a tutorial on how to build a simple Web app using the LDflex as a query language to extract data from distributed RDF Knowledge Graphs.","name":"Build Web app using LDflex and Solid","url":"https://github.com/julianrojas87/Tutorial-ISWC2019-LDflex-on-React/wiki/Tutorial-Walkthrough"},{"description":"This is a tutorial on how to build a simple Solid app using GraphQL-LD. Concretely, this tutorial explains how to build a Solid profile viewer in React using the GraphQL-LD Solid React Components.","name":"Build Web app using GraphQL-LD and Solid","url":"https://github.com/comunica/Tutorial-Solid-GraphQL-LD-Profile-Viewer/wiki/Tutorial-walkthrough"}]}]}`),

      // '/education/master-theses'
      "{ id(_:KNOWS) member { slug @single year(_:\"2021\") subject @single { keywords name @single } contactPoint { id @single givenName @single familyName @single } }}":
        JSON.parse(`{"data":[{"member":[{"subject":{"keywords":[" linked data"," mobility"," solid"," traffic "," web API","Open data"],"name":"A Linked Data Event Stream for Telraam/WeCount 's Open Data"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"a-linked-data-event-stream-for-telraam-wecount--s-open-data"},{"subject":{"keywords":["Linked Data","Open Data","big data","mobility","route planning","smart cities"],"name":"A route planner based on Open Data"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"slug":"a-route-planner-based-on-open-data"},{"subject":{"keywords":[" AI"," Artificial Intelligence"," Data Retrieval"," Linked Data"," Semantic Web"," geospatial"," open data","Indexing"],"name":"A tool for the mayor of Ghent: querying geospatial data on Web-scale"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"a-tool-for-the-mayor-of-ghent:-querying-geospatial-data-on-web-scale"},{"subject":{"keywords":["Linked Data","AI ","Apache NiFi","Artificial Intelligence","Big Data","Data Processing","RML","cloud computing","pipelines"],"name":"A Workbench based on NiFi: Linked Open Data at your Fingertips"},"contactPoint":[{"givenName":"Ben","familyName":"De Meester","id":"https://ben.de-meester.org/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Anastasia","familyName":"Δήμου","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Δήμου","id":"https://natadimou.com/#me"}],"slug":"a-workbench-based-on-nifi:-linked-open-data-at-your-fingertips"},{"subject":{"keywords":["Artificial Intelligence","AI","ML","Machine LEarning","RDF","SQL","query","view"],"name":"Address the complexity of the Web with views"},"contactPoint":[{"givenName":"Ben","familyName":"De Meester","id":"https://ben.de-meester.org/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Anastasia","familyName":"Δήμου","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Δήμου","id":"https://natadimou.com/#me"}],"slug":"address-the-complexity-of-the-web-with-views"},{"subject":{"keywords":[" Linked Data"," RDF"," RDF*"," SPARQL"," decentralization"," property graphs","Webdevelopment"],"name":"Analysis of Property Graphs in SPARQL engines"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"}],"slug":"analysis-of-property-graphs-in-sparql-engines"},{"subject":{"keywords":[" Linked Data"," RDF"," SPARQL"," decentralization","Webdevelopment"," querying"," security"],"name":"Analyzing Security when Querying over Decentralized Environments"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"}],"slug":"analyzing-security-when-querying-over-decentralized-environments"},{"subject":{"keywords":[" Authentication"," Privacy "," Solid","Decentralization"],"name":"Authentication to decentralized data sources via Walder"},"contactPoint":[{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"},{"givenName":"Pieter","familyName":"Heyvaert","id":"https://pieterheyvaert.com/#me"}],"slug":"authentication-to-decentralized-data-sources-via-walder"},{"subject":{"keywords":[" Knowledge Graph"," Linked Data "," Route Planning"," Train","Railway"],"name":"Automatic railway compatibility verification across Europe"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"slug":"automatic-railway-compatibility-verification-across-europe"},{"subject":{"keywords":["Linked Data","Artificial Intelligence","AI","Data Science","Knowledge Graph","Semantic Web"],"name":"Belgian parliamentary votes as a knowledge graph"},"contactPoint":[{"givenName":"Ben","familyName":"De Meester","id":"https://ben.de-meester.org/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Anastasia","familyName":"Δήμου","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Δήμου","id":"https://natadimou.com/#me"}],"slug":"belgian-parliamentary-votes-as-a-knowledge-graph"},{"subject":{"keywords":[" Linked Data","AI"," Solid"," Biohacking"," Data Analysis"," Decentralization"," Health"," Machine Learning"," Mobile Health"," Productivity"],"name":"Boosting analytical potential of health tracking data using RML and Solid"},"contactPoint":[{"givenName":"Ben","familyName":"De Meester","id":"https://ben.de-meester.org/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Anastasia","familyName":"Δήμου","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Δήμου","id":"https://natadimou.com/#me"}],"slug":"boosting-analytical-potential-of-health-tracking-data-using-rml-and-solid"},{"subject":{"keywords":[" AI"," Artificial Intelligence"," Data Retrieval"," Linked Data"," Semantic Web","Indexing"," open data "],"name":"Building a data strategy for the Deparment of Education in Flanders"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"building-a-data-strategy-for-the-deparment-of-education-in-flanders"},{"subject":{"keywords":[" Linked Data"," RDF"," decentralization","Webdevelopment"," blockchain"],"name":"Caching and replication in decentralized Linked Data environments"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"}],"slug":"caching-and-replication-in-decentralized-linked-data-environments"},{"subject":{"keywords":["Linked Data"," Semantic Web"," Collaborative Storytelling"," Role Playing Games "],"name":"Collaborative Storytelling on the Semantic Web"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"collaborative-storytelling-on-the-semantic-web"},{"subject":{"keywords":[" AI"," Artificial Intelligence","Decentralization"," Machine Learning"," Federation"," Learning"," ML "],"name":"Competitive knowledge graph generation"},"contactPoint":[{"givenName":"Ben","familyName":"De Meester","id":"https://ben.de-meester.org/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Anastasia","familyName":"Δήμου","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Δήμου","id":"https://natadimou.com/#me"}],"slug":"competitive-knowledge-graph-generation"},{"subject":{"keywords":[" Route Planning"," Compilers"," Emscripten"," Programming Languages "," Rust","WebAssembly"],"name":"Cross-platform and efficient route planning with WebAssembly"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"cross-platform-and-efficient-route-planning-with-webassembly"},{"subject":{"keywords":[" IIIF"," linked open data","Culture"],"name":"Cultural heritage with IIIF and event streams"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"slug":"cultural-heritage-with-iiif-and-event-streams"},{"subject":{"keywords":["Artificial Intelligence","AI","ML","Decentralization","GDPR","Learning","Machine Learning","privacy"],"name":"Decide yourself what happens with your data"},"contactPoint":[{"givenName":"Ben","familyName":"De Meester","id":"https://ben.de-meester.org/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Anastasia","familyName":"Δήμου","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Δήμου","id":"https://natadimou.com/#me"}],"slug":"decide-yourself-what-happens-with-your-data"},{"subject":{"keywords":[" Artificial Intelligence"," Machine Learning"," Knowledge Graphs "," Reasoning"," Semantics","Role Playing Games"],"name":"Dungeons and Dragons as a Testbed for Diverse Sequential Recommender Systems"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"dungeons-and-dragons-as-a-testbed-for-diverse-sequential-recommender-systems"},{"subject":{"keywords":[" Linked Data"," Solid","querying"],"name":"Efficient and secure querying of Linked Data federations"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"}],"slug":"efficient-and-secure-querying-of-linked-data-federations"},{"subject":{"keywords":["Linked Data","Semantic Web","Data Streams","Internet of Things","Semantic Sensor Web","open data","smart cities "],"name":"Exposing IoT Streams on the Semantic Web"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"slug":"exposing-iot-streams-on-the-semantic-web"},{"subject":{"keywords":["Data Science","Algorithms","Graphs","Hiking","Route Planning"],"name":"Help amateur hikers to find their way through the woods"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"help-amateur-hikers-to-find-their-way-through-the-woods"},{"subject":{"keywords":["Artificial Intelligence","cloud computing","AI","Decentralization","GDPR","Learning","privacy","data platforms"],"name":"How can you implement your right to be forgotten?"},"contactPoint":[{"givenName":"Ben","familyName":"De Meester","id":"https://ben.de-meester.org/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Anastasia","familyName":"Δήμου","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Δήμου","id":"https://natadimou.com/#me"}],"slug":"how-can-you-implement-your-right-to-be-forgotten"},{"subject":{"keywords":["automated generation","data pod","indexing","shapes"],"name":"Indexing personal data pods using automated data shape generation"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"indexing-personal-data-pods-using-automated-data-shape-generation"},{"subject":{"keywords":["Artificial Intelligence","Big Data","cloud computing","AI","ML","Machine Learning","Data Streams","Internet of Things","Apache Flink","IoT","Streams","frameworks"],"name":"Intelligent Sensors"},"contactPoint":[{"givenName":"Ben","familyName":"De Meester","id":"https://ben.de-meester.org/#me"},{"givenName":"Anastasia","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Dimou","id":"https://natadimou.com/#me"},{"givenName":"Anastasia","familyName":"Δήμου","id":"https://natadimou.com/#me"},{"givenName":"Αναστασία","familyName":"Δήμου","id":"https://natadimou.com/#me"}],"slug":"intelligent-sensors"},{"subject":{"keywords":["Linked Data","Semantic Web","Cultural Heritage","hypermedia","open data "],"name":"Making data about artworks in Ghent findable, accessible, interoperable and reusable"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"making-data-about-artworks-in-ghent-findable,-accessible,-interoperable-and-reusable"},{"subject":{"keywords":["Linked Data","decentralized network","query evaluation","query optimization"],"name":"Optimizing query evaluation over distributed data pods"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"optimizing-query-evaluation-over-distributed-data-pods"},{"subject":{"keywords":["Linked Data","RDF","Webdevelopment","Querying","SPARQL","decentralization"],"name":"Performance evaluation of the variety of Linked Data Interfaces"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"}],"slug":"performance-evaluation-of-the-variety-of-linked-data-interfaces"},{"subject":{"keywords":[" SOLID"," data ecosystem"," digital platforms"," engineering economy"," information technology "," techno-economic analysis","personal data vaults"],"name":"Personal data vaults: techno-economic analysis and potential impact on the data ecosystem"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Sofie","familyName":"Verbrugge","id":"https://data.knows.idlab.ugent.be/person/sofieverbrugge/#me"}],"slug":"personal-data-vaults:-techno-economic-analysis-and-potential-impact-on-the-data-ecosystem"},{"subject":{"keywords":[" mobility"," solid"," Linked Data","open data"," AI "," GDPR"," artificial intelligence"," route planning"," semantic web"," smart cities"],"name":"Personalized and privacy-aware route planning on the Web"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"personalized-and-privacy-aware-route-planning-on-the-web"},{"subject":{"keywords":[" AI"," open data"," artificial intelligence"," deep learning"," tensorflow ","smart city"],"name":"Predict how busy a certain part of the city is with Open Data"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"slug":"predict-how-busy-a-certain-part-of-the-city-is-with-open-data"},{"subject":{"keywords":[" Air Quality "," Linked Open Data"," Semantisch Web"," Smart City","Digital Twin"],"name":"Prototyping with Open Urban Digital Twins"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"slug":"prototyping-with-open-urban-digital-twins"},{"subject":{"keywords":[" Linked Data"," Semantic Web"," open data","Internet of Things"," Data Streams"," Semantic Sensor Web"," smart cities "],"name":"Publishing time series snippets on the Web"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"}],"slug":"publishing-time-series-snippets-on-the-web"},{"subject":{"keywords":[" Linked Data"," RDF"," SPARQL","Webdevelopment"," Querying"," WebAssembly"],"name":"Query Optimization using WebAssembly"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"}],"slug":"query-optimization-using-webassembly"},{"subject":{"keywords":[" Linked Data"," RDF"," SPARQL","Webdevelopment"," Querying"," WebGL"],"name":"Query Optimization using WebGL"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"}],"slug":"query-optimization-using-webgl"},{"subject":{"keywords":["Big Data"," Decentralization "," Stream Processing"],"name":"Taming decentralized Big Data Streams"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Femke","familyName":"Ongenae","id":"https://data.knows.idlab.ugent.be/person/femkeongenae/#me"}],"slug":"taming-decentralized-big-data-streams"},{"subject":{"keywords":[" Data Retrieval"," Linked Data","Indexing"," Semantic Web "],"name":"Web-scale discovery of geospatial data"},"contactPoint":[{"givenName":"Pieter","familyName":"Colpaert","id":"https://pietercolpaert.be/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"}],"slug":"web-scale-discovery-of-geospatial-data"},{"subject":{"keywords":[" Linked Data"," RDF","Webdevelopment"," JavaScript"," Parsers"," Parsing"],"name":"Writing a highly efficient JSON-LD parser for specific frames"},"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me"},{"givenName":"Ruben","familyName":"Taelman","id":"https://www.rubensworks.net/#me"}],"slug":"writing-a-highly-efficient-json-ld-parser-for-specific-frames"}]}]}`),

      // '/education/master-thesis/{year}/{slug} (expecting 38 entries)'
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),
      // "":
      //   JSON.parse(``),

      // '/team'
      "{ id(_:team) employee { id @single givenName @single familyName @single img @single title @single email @single role @single }}":
        JSON.parse(`{"data":[{"employee":[{"givenName":"Ruben","familyName":"Verborgh","img":"https://ruben.verborgh.org/images/ruben.jpg","title":"Professor of Decentralized Web technology","email":"mailto:ruben.verborgh@ugent.be","id":"https://ruben.verborgh.org/profile/#me","role":"https://data.knows.idlab.ugent.be/person/office/#GroupLead"},{"givenName":"Ruben","familyName":"Verborgh","img":"https://ruben.verborgh.org/images/ruben.jpg","title":"Professor of Decentralized Web technology","email":"mailto:ruben.verborgh@ugent.be","id":"https://ruben.verborgh.org/profile/#me","role":"https://data.knows.idlab.ugent.be/person/office/#GroupLead"},{"givenName":"Ruben","familyName":"Verborgh","img":"https://ruben.verborgh.org/images/ruben.jpg","title":"Professor of Decentralized Web technology","email":"mailto:ruben.verborgh@ugent.be","id":"https://ruben.verborgh.org/profile/#me","role":"https://data.knows.idlab.ugent.be/person/office/#GroupLead"},{"givenName":"Ruben","familyName":"Verborgh","img":"https://ruben.verborgh.org/images/ruben.jpg","title":"Professor of Decentralized Web technology","email":"mailto:ruben.verborgh@ugent.be","id":"https://ruben.verborgh.org/profile/#me","role":"https://data.knows.idlab.ugent.be/person/office/#GroupLead"},{"givenName":"Erik","familyName":"Mannens","img":"https://data.knows.idlab.ugent.be/person/erikmannens/profile.jpg","title":"Research Valorization Director and Prof. Semantic Intelligence","email":"mailto:Erik.Mannens@UGent.be","id":"https://data.knows.idlab.ugent.be/person/erikmannens/#me","role":"https://data.knows.idlab.ugent.be/person/office/#ClusterLead"},{"email":"mailto:herbert.vandesompel@ugent.be","givenName":"Herbert","familyName":"Van de Sompel","img":"https://hvdsomp.info/images/herbert_profile.jpg","title":"Guest Professor","id":"https://hvdsomp.info/#i","role":"https://data.knows.idlab.ugent.be/person/office/#GuestProfessor"},{"email":"mailto:hvdsomp@gmail.com","givenName":"Herbert","familyName":"Van de Sompel","img":"https://hvdsomp.info/images/herbert_profile.jpg","title":"Guest Professor","id":"https://hvdsomp.info/#i","role":"https://data.knows.idlab.ugent.be/person/office/#GuestProfessor"},{"givenName":"Ben","familyName":"De Meester","img":"https://gravatar.com/avatar/92707f5c614704469138dbc868efb7c0?s=320","title":"Postdoctoral Researcher","email":"mailto:ben.demeester@ugent.be","id":"https://ben.de-meester.org/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Anastasia","familyName":"Dimou","img":"https://natadimou.com/img/me.jpg","title":"Team and Research Lead","email":"mailto:anastasia.dimou@ugent.be","id":"https://natadimou.com/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Αναστασία","familyName":"Dimou","img":"https://natadimou.com/img/me.jpg","title":"Team and Research Lead","email":"mailto:anastasia.dimou@ugent.be","id":"https://natadimou.com/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Anastasia","familyName":"Δήμου","img":"https://natadimou.com/img/me.jpg","title":"Team and Research Lead","email":"mailto:anastasia.dimou@ugent.be","id":"https://natadimou.com/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Αναστασία","familyName":"Δήμου","img":"https://natadimou.com/img/me.jpg","title":"Team and Research Lead","email":"mailto:anastasia.dimou@ugent.be","id":"https://natadimou.com/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Pieter","familyName":"Colpaert","img":"https://pietercolpaert.be/img/pc.jpg","title":"Post-doctoral researcher","email":"mailto:pieter@openknowledge.be","id":"https://pietercolpaert.be/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Pieter","familyName":"Heyvaert","img":"https://pieterheyvaert.com/img/profile.jpg","title":"Development Lead and Developer Advocate","email":"mailto:pieter.heyvaert@ugent.be","id":"https://pieterheyvaert.com/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Pieter","familyName":"Heyvaert","img":"https://pieterheyvaert.com/img/profile.jpg","title":"Development Lead and Developer Advocate","email":"mailto:pieter.heyvaert@ugent.be","id":"https://pieterheyvaert.com/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Pieter","familyName":"Heyvaert","img":"https://pieterheyvaert.com/img/profile.jpg","title":"Development Lead and Developer Advocate","email":"mailto:pieter.heyvaert@ugent.be","id":"https://pieterheyvaert.com/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Pieter","familyName":"Heyvaert","img":"https://pieterheyvaert.com/img/profile.jpg","title":"Development Lead and Developer Advocate","email":"mailto:pieter.heyvaert@ugent.be","id":"https://pieterheyvaert.com/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Ruben","familyName":"Taelman","email":"mailto:ruben.taelman@ugent.be","img":"https://www.rubensworks.net/img/ruben.jpg","title":"Post-doctoral Web Researcher","id":"https://www.rubensworks.net/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Ruben","familyName":"Taelman","email":"mailto:rubensworks@gmail.com","img":"https://www.rubensworks.net/img/ruben.jpg","title":"Post-doctoral Web Researcher","id":"https://www.rubensworks.net/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PostDoc"},{"givenName":"Dwight","familyName":"Van Lancker","img":"https://data.knows.idlab.ugent.be/person/dwightvanlancker/profile.jpg","title":"External PhD student","email":"mailto:dwight.vanlancker@ugent.be","id":"https://data.knows.idlab.ugent.be/person/dwightvanlancker/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Gerald","familyName":"Haesendonck","img":"https://www.ugent.be/ea/idlab/img/members/geraldhaesendonck-jpg/","title":"PhD-Student","email":"mailto:gerald.haesendonck@ugent.be","id":"https://data.knows.idlab.ugent.be/person/geraldh/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Harm","familyName":"Delva","img":"https://data.knows.idlab.ugent.be/person/harm/profile.jpeg","title":"PhD Student","email":"mailto:harm.delva@ugent.be","id":"https://data.knows.idlab.ugent.be/person/harm/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Ioannis","familyName":"Chrysakis","img":"https://data.knows.idlab.ugent.be/person/ioannischrysakis/profile.jpg","title":"External PhD student","email":"mailto:ioannis.chrysakis@ugent.be","id":"https://data.knows.idlab.ugent.be/person/ioannischrysakis/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Jeroen","familyName":"Werbrouck","img":"https://data.knows.idlab.ugent.be/person/jeroenwerbrouck/profile.jpg","title":"PhD student","email":"mailto:jeroen.werbrouck@ugent.be","id":"https://data.knows.idlab.ugent.be/person/jeroenwerbrouck/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Joachim","familyName":"Van Herwegen","img":"https://data.knows.idlab.ugent.be/person/joachimvh/profile.jpg","title":"PhD Student","email":"mailto:joachim.vanherwegen@ugent.be","id":"https://data.knows.idlab.ugent.be/person/joachimvh/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Martin","familyName":"Vanbrabant","img":"https://data.knows.idlab.ugent.be/person/martinvanbrabant/profile.jpg","title":"Researcher Semantic Web","email":"mailto:martin.vanbrabant@ugent.be","id":"https://data.knows.idlab.ugent.be/person/martinvanbrabant/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Raf","familyName":"Buyle","img":"https://data.knows.idlab.ugent.be/person/rafbuyle/profile.jpg","title":"External PhD student","email":"mailto:raf.buyle@ugent.be","id":"https://data.knows.idlab.ugent.be/person/rafbuyle/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Ruben","familyName":"Dedecker","img":"https://data.knows.idlab.ugent.be/person/rubend/profile.jpg","title":"PhD Student","email":"mailto:Ruben.Dedecker@UGent.be","id":"https://data.knows.idlab.ugent.be/person/rubend/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Thomas","familyName":"Delva","img":"https://data.knows.idlab.ugent.be/person/thomas/profile.jpg","title":"PhD Researcher","email":"mailto:thomas.delva@ugent.be","id":"https://data.knows.idlab.ugent.be/person/thomas/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Gertjan","familyName":"De Mulder","img":"https://data.knows.idlab.ugent.be/person/gertjandm/gddmulde.png","title":"Developer","email":"mailto:gertjan.demulder@ugent.be","id":"https://data.knows.idlab.ugent.be/person/gertjandm/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Dylan","familyName":"Van Assche","img":"https://dylanvanassche.be/assets/img/avatar.png","title":"Semantic Web PhD Researcher","email":"mailto:dylan.vanassche@ugent.be","id":"https://dylanvanassche.be/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Dylan","familyName":"Van Assche","img":"https://dylanvanassche.be/assets/img/avatar.png","title":"Semantic Web PhD Researcher","email":"mailto:dylan.vanassche@ugent.be","id":"https://dylanvanassche.be/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Dylan","familyName":"Van Assche","img":"https://dylanvanassche.be/assets/img/avatar.png","title":"Semantic Web PhD Researcher","email":"mailto:dylan.vanassche@ugent.be","id":"https://dylanvanassche.be/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Dylan","familyName":"Van Assche","img":"https://dylanvanassche.be/assets/img/avatar.png","title":"Semantic Web PhD Researcher","email":"mailto:dylan.vanassche@ugent.be","id":"https://dylanvanassche.be/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Julián Andrés","familyName":"Rojas Meléndez","img":"https://julianrojas.org/resources/img/me.jpg","title":"PhD. Researcher","email":"mailto:julianandres.rojasmelendez@ugent.be","id":"https://julianrojas.org/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Julián","familyName":"Rojas Meléndez","img":"https://julianrojas.org/resources/img/me.jpg","title":"PhD. Researcher","email":"mailto:julianandres.rojasmelendez@ugent.be","id":"https://julianrojas.org/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Sven","familyName":"Lieber","img":"https://sven-lieber.org/img/sven-lieber.jpg","title":"PhD researcher semantic intelligence","email":"mailto:sven.lieber@ugent.be","id":"https://sven-lieber.org/profile#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Sven","familyName":"Lieber","img":"https://sven-lieber.org/img/sven-lieber.jpg","title":"PhD researcher semantic intelligence","email":"mailto:sven.lieber@ugent.be","id":"https://sven-lieber.org/profile#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Sven","familyName":"Lieber","img":"https://sven-lieber.org/img/sven-lieber.jpg","title":"PhD researcher semantic intelligence","email":"mailto:sven.lieber@ugent.be","id":"https://sven-lieber.org/profile#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Sven","familyName":"Lieber","img":"https://sven-lieber.org/img/sven-lieber.jpg","title":"PhD researcher semantic intelligence","email":"mailto:sven.lieber@ugent.be","id":"https://sven-lieber.org/profile#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Brecht","familyName":"Van de Vyvere","email":"mailto:brecht.vandevyvere@ugent.be","img":"https://brechtvdv.github.io/profile.jpg","title":"PhD researcher","id":"https://w3id.org/people/brechtvdv/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Brecht","familyName":"Van de Vyvere","email":"mailto:brecht.vandevyvere@ugent.be","img":"https://brechtvdv.github.io/profile.jpg","title":"PhD researcher","id":"https://w3id.org/people/brechtvdv/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Brecht","familyName":"Van de Vyvere","email":"mailto:brecht.vandevyvere@ugent.be","img":"https://brechtvdv.github.io/profile.jpg","title":"PhD researcher","id":"https://w3id.org/people/brechtvdv/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Brecht","familyName":"Van de Vyvere","email":"mailto:brecht.vandevyvere@ugent.be","img":"https://brechtvdv.github.io/profile.jpg","title":"PhD researcher","id":"https://w3id.org/people/brechtvdv/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Brecht","familyName":"Van de Vyvere","email":"mailto:br5cht@hotmail.com","img":"https://brechtvdv.github.io/profile.jpg","title":"PhD researcher","id":"https://w3id.org/people/brechtvdv/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Brecht","familyName":"Van de Vyvere","email":"mailto:br5cht@hotmail.com","img":"https://brechtvdv.github.io/profile.jpg","title":"PhD researcher","id":"https://w3id.org/people/brechtvdv/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Brecht","familyName":"Van de Vyvere","email":"mailto:br5cht@hotmail.com","img":"https://brechtvdv.github.io/profile.jpg","title":"PhD researcher","id":"https://w3id.org/people/brechtvdv/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"},{"givenName":"Brecht","familyName":"Van de Vyvere","email":"mailto:br5cht@hotmail.com","img":"https://brechtvdv.github.io/profile.jpg","title":"PhD researcher","id":"https://w3id.org/people/brechtvdv/#me","role":"https://data.knows.idlab.ugent.be/person/office/#PreDoc"}]}]}`),

      // '/contact'
      "{ id(_:KNOWS) contactPoint { id @single givenName @single familyName @single img @single } location @single { name @single address @single }}":
        JSON.parse(`{"data":[{"contactPoint":[{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me","img":"https://ruben.verborgh.org/images/ruben.jpg"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me","img":"https://ruben.verborgh.org/images/ruben.jpg"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me","img":"https://ruben.verborgh.org/images/ruben.jpg"},{"givenName":"Ruben","familyName":"Verborgh","id":"https://ruben.verborgh.org/profile/#me","img":"https://ruben.verborgh.org/images/ruben.jpg"}],"location":{"name":"AA Tower","address":"https://data.vlaanderen.be/id/adres/20470097"}}]}`)
    };
  }

/**
   * Instantiates the variables in the given GraphQL-LD query using the given path variables and query parameters,
   * then executes the given GraphQL-LD query using Comunica.
   *
   * @param graphQLLDInfo - Object containing the Comunica configuration, cache setting, the GraphQL query and the JSON-LD context.
   * @param pathParams - Object containing path parameters to value mapping.
   * @param queryParams - Object containing query parameter to value mapping.
   * @returns {Promise<>} - GraphQL-LD query results.
   */
  async handle(graphQLLDInfo, pathParams = {}, queryParams = {}) {
    const newQueries = Object.keys(graphQLLDInfo.queries).reduce((acc, val) => {
      const missingRequiredParameter = this._areRequiredParametersMissing(graphQLLDInfo.parameters, pathParams, queryParams);

      if (missingRequiredParameter) {
          const err = new Error(`Not all required parameters have a value: ${missingRequiredParameter.name} (${missingRequiredParameter.in} parameter).`);
          err.type = 'GRAPHQL-MISSINGREQUIREDPARAMETERS';

          throw err;
      }

      const pathParamsFromGraphQLLDInfo = {};
      const queryParamsFromGraphQLLDInfo = {};

      for (const key in graphQLLDInfo.parameters) {
        const value = graphQLLDInfo.parameters[key];

        if (value.in === 'path') {
          pathParamsFromGraphQLLDInfo[key] = value;
        } else {
          queryParamsFromGraphQLLDInfo[key] = value;
        }
      }

      const query = graphQLLDInfo.queries[val].query;
      acc[val] = {};
      acc[val].query = this._substituteQueryParams(this._substituteVariables(query, pathParams, pathParamsFromGraphQLLDInfo), queryParams, queryParamsFromGraphQLLDInfo);
      acc[val].options = graphQLLDInfo.queries[val].options;
      return acc;
    }, {});

    // HACK
    // const clientConfig = {
    //   context: graphQLLDInfo.context,
    // };

    // Sort the data sources before looking in cache
    graphQLLDInfo.comunicaConfig.sources.sort();

    // HACK
    // if (!(graphQLLDInfo.comunicaConfig.sources.toString() in this.comunicaEngineSourcesMap)) {
    //   this.comunicaEngineSourcesMap[graphQLLDInfo.comunicaConfig.sources.toString()] = new QueryEngineComunica(graphQLLDInfo.comunicaConfig);
    //
    //   if (this.logger) {
    //     this.logger.verbose('Creating new Comunica query engine');
    //   }
    // } else {
    //   if (this.logger) {
    //     this.logger.verbose('Reusing existing Comunica query engine');
    //   }
    // }
    //
    // clientConfig.queryEngine = this.comunicaEngineSourcesMap[graphQLLDInfo.comunicaConfig.sources.toString()];
    //
    // if (!graphQLLDInfo.cache) {
    //   await clientConfig.queryEngine.comunicaEngine.invalidateHttpCache();
    // }

    if (this.logger) {
      this.logger.verbose(JSON.stringify(newQueries));
    }

    // HACK
    // const client = new Client(clientConfig);
    const results = {};

    for (const key of Object.keys(newQueries)) {
      try {
        // results[key] = await client.query({
        //   query: newQueries[key].query
        // });
        // HACK
        results[key] = this.hardcodedQueryResults[newQueries[key].query];
      } catch (error) {
        if (this.logger) {
          this.logger.debug(error);
        }

        throw new Error(`Error during execution of GraphQL-LD query "${newQueries[key].query}".`);
      }

      if (this.logger) {
        this.logger.verbose(JSON.stringify(results[key]));
      }
    }


    //check if queries have options
    for (const key of Object.keys(newQueries)) {
      if (newQueries[key].options){
        //results need to be sorted
        if (newQueries[key].options.sort){
          const original = JP.query(results[key].data, newQueries[key].options.sort.object);
          const sorted = this._sortBy(original, newQueries[key].options.sort.selectors);
          let sortedData = [];
          sorted.forEach(object => {
            sortedData.push(results[key].data[original.indexOf(object)]);
          });
          results[key].data = sortedData;
        }
        //duplicates need to be filtered out of the results
        if (newQueries[key].options['remove-duplicates']){
          results[key].data =
              this._removeDuplicates(results[key].data, newQueries[key].options['remove-duplicates']);
        }
      }
    }

    return results;
  }

  /**
   * Instantiates the given variables in the query.
   *
   * @param query
   * @param variables
   *
   * @returns string (newQuery)
   */
  _substituteVariables(query, variables, definedParameters) {
    const keys = Object.keys(variables);
    if (keys.length > 0) {
      let newQuery = query;
      keys.forEach(key => {
        let val = variables[key];

        if (definedParameters[key].type === 'integer') {
          val = parseInt(val);
        } else {
          val = `"${val}"`;
        }

        newQuery = newQuery.replace('$' + key, val);
      });
      return newQuery;
    } else {
      return query;
    }
  };

  /**
   * Instantiates the given query parameters in the query.
   * Pagination parameters are converted to GraphQL format.
   *
   * @param query {string} - GraphQL-LD query
   * @param params
   * @param definedParameters
   *
   * @returns string (newQuery)
   */
  _substituteQueryParams(query, params, definedParameters) {
    const keys = params && Object.keys(params);
    if (keys && keys.length > 0) {
      // Pagination parameters to GraphQL format
      if (keys.includes('page') && keys.includes('limit')) {
        params.limit = Number(params.limit);
        params.offset = Number(params.page) * params.limit;
      }
      delete params.page;
      return this._substituteVariables(query, params, definedParameters);
    } else {
      return query;
    }
  };

  /**
   * Removes the duplicates from the data who have the same value.
   *
   * @param data the data retrieved by the query
   * @param options the options that say which duplicates need to be removed
   *
   * @returns array of data with no more duplicates
   */
  _removeDuplicates(data, options) {
    let uniqueValue = [];
    let uniqueData = [];
    let objects = JP.query(data, options.object);

    objects.forEach((object, index) => {
      let value = JP.query(object, options.value)[0];
      if (uniqueValue.indexOf(value) === -1){
        uniqueValue.push(value);
        uniqueData.push(data[index]);
      }
    });

    return uniqueData;
  }


  /**
   *Sorts the array by the chosen selectors and given order (no order given === asc).
   *
   * @param array array of data given by a certain query
   * @param selectors the selectors where the results need to be sorted by
   * @returns sorted array of data
   */
  _sortBy(array, selectors) {
    return array.concat().sort((a, b) => {
      for (let selector of selectors) {
        let reverse = selector.order ? -1 : 1;

        a = selector.value ? JP.query(a, selector.value)[0] : JP.query(a,selector)[0];
        b = selector.value ? JP.query(b, selector.value)[0] : JP.query(b,selector)[0];

        if (a.toUpperCase() > b.toUpperCase()) {
          return reverse;
        }
        if (a.toUpperCase() < b.toUpperCase()) {
          return -1 * reverse;
        }
      }
      return 0;
    });
  }

  _areRequiredParametersMissing(definedParams = {}, actualPathParams, actualQueryParams) {
    const definedParamNames = Object.keys(definedParams);

    if (definedParamNames.length === 0) {
      return false;
    }

    let i = 0;
    let definedParamName = definedParamNames[i];
    let definedParam = definedParams[definedParamName];
    let paramsToLookAt = definedParam.in === 'query' ? actualQueryParams : actualPathParams;

    while (i < definedParamNames.length &&
    (!definedParam.required || (definedParam.required && paramsToLookAt[definedParamName] !== undefined))) {
      i ++;

      if (i < definedParamNames.length) {
        definedParamName = definedParamNames[i];
        definedParam = definedParams[definedParamName];
        paramsToLookAt = definedParam.in === 'query' ? actualQueryParams : actualPathParams;
      }
    }

    if (i === definedParamNames.length) {
      return false;
    } else {
      let missingParam = {name: definedParamName};
      missingParam = {...missingParam, ...definedParam};

      return missingParam;
    }
  }
};
